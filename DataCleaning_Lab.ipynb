{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "517de334-644a-4ba9-889a-1c89c52da0ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fe5913c8730>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from api.database import *\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import spacy\n",
    "import re\n",
    "from collections import Counter\n",
    "import unicodedata\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)\n",
    "#python -m spacy download corpus_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3915156c-e593-4ff4-8115-c69d44e7a39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_df_loading():\n",
    "    d = get_df(\"SELECT nom, text, x, y from deputes join texts on texts.deputes_id = deputes.id LIMIT 10\")\n",
    "    df = pd.DataFrame(d)\n",
    "    print(df)\n",
    "\n",
    "d = get_df(\"SELECT nom, text, x, y from deputes join texts on texts.deputes_id = deputes.id LIMIT 10\")\n",
    "df = pd.DataFrame(d)\n",
    "corpus_a = \"fr_dep_news_trf\"\n",
    "corpus_e = \"fr_core_news_sm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "912afa5f-304e-4a69-9fc9-5669a7540471",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def separe_to_sentences(text, efficiency = True):\n",
    "    corpus = corpus_e if efficiency else corpus_a\n",
    "    nlp = spacy.load(corpus)\n",
    "    doc = nlp(text)\n",
    "    assert doc.has_annotation(\"SENT_START\")\n",
    "    return [unicodedata.normalize(\"NFKD\", sent.text)  for sent in doc.sents]\n",
    "\n",
    "def process_text(text, efficiency = True):\n",
    "    text = re.sub(r'\\([^)]*\\)', '', text)\n",
    "    corpus = corpus_e if efficiency else corpus_a\n",
    "    nlp = spacy.load(corpus)\n",
    "    doc = nlp(text)\n",
    "    t = [token.lemma_.lower() for token in doc if not token.is_stop and token.is_alpha]\n",
    "    return t\n",
    "\n",
    "def create_lexic(d2, size = 1000):\n",
    "    df2 = pd.DataFrame(d2)\n",
    "    df2[\"cleaned_text\"] = df2[\"text\"].apply(process_text)\n",
    "    df2[\"n_words\"] = df2[\"cleaned_text\"].apply(len)\n",
    "    df2 = df2[df2.n_words > 1]\n",
    "    c = dict(Counter(df2[\"cleaned_text\"].sum()))\n",
    "    so = sorted(c.items(), key = lambda x:x[1], reverse = True)\n",
    "    d = dict(so[:size])\n",
    "    return list(d.keys())\n",
    "\n",
    "\n",
    "    \n",
    "def separe_dictionnary_by_sentences(d):\n",
    "    d2 = {k:[] for k in d.keys()}\n",
    "    for nom, text, x, y in tqdm(list(zip(d[\"nom\"], d[\"text\"], d[\"x\"], d[\"y\"]))):\n",
    "        sentences = separe_to_sentences(text, efficiency = True)\n",
    "        for sentence in sentences:\n",
    "            if len(sentences) < 15:\n",
    "                continue\n",
    "            d2[\"nom\"].append(nom)\n",
    "            d2[\"x\"].append(x)\n",
    "            d2[\"y\"].append(y)\n",
    "            d2[\"text\"].append(sentence)\n",
    "    return d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28640512-27dd-4139-85e4-2dcee122666d",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = get_df(\"SELECT nom, text, x, y from deputes join texts on texts.deputes_id = deputes.id LIMIT 10\")\n",
    "df = pd.DataFrame(d)\n",
    "lexic = create_lexic(d, size = 1000)\n",
    "df[\"cleaned_text\"] = df[\"text\"].apply(process_text)\n",
    "df[\"cleaned_text\"] = df[\"cleaned_text\"].apply(lambda x:[i for i in x if i in lexic])\n",
    "df[\"text\"] = df[\"cleaned_text\"].apply(lambda x:\" \".join(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15bbdce-67b9-4ea9-8662-8415389b7693",
   "metadata": {},
   "source": [
    "## Without embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b1986321-ed5e-4977-ab6a-a1b6076fbfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = get_df(\"SELECT nom, text, x, y from deputes join texts on texts.deputes_id = deputes.id LIMIT 100\")\n",
    "df = pd.DataFrame(d)\n",
    "df[\"cleaned_text\"] = df[\"text\"].apply(process_text)\n",
    "#lexic = create_lexic(d, size = 1000)\n",
    "#df[\"cleaned_text\"] = df[\"cleaned_text\"].apply(lambda x:[i for i in x if i in lexic])\n",
    "df[\"text\"] = df[\"cleaned_text\"].apply(lambda x:\" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f31e1385-020f-41fd-9a10-febe13ffa9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(list(df[\"text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0090842d-cbec-48df-9143-4ecec98908de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x2772 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 134 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.transform([df[\"text\"][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3e90a405-2b04-48a3-8fc9-0c4e399b12aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2772,)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names_out().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9cbde22a-ae67-40c2-a518-d3d9146f5990",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFIDF_NN(nn.Module):\n",
    "\n",
    "    def __init__(self, vect, hidden_size = 100):\n",
    "        super(TFIDF_NN, self).__init__()\n",
    "        self.vectorizer = vect\n",
    "        vocab_size = vect.get_feature_names_out().shape[0]\n",
    "        self.linear1 = nn.Linear(vocab_size, hidden_size)\n",
    "        self.output = nn.Linear(hidden_size, 2)\n",
    "\n",
    "\n",
    "    def forward(self, text):\n",
    "        inputs = torch.tensor(self.vectorizer.transform(text).toarray()).float()\n",
    "        h1 = F.relu(self.linear1(inputs))\n",
    "        output = self.output(h1)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "df6544b7-3ef1-4368-9c29-3aa265911733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 25718920.0\n",
      "250 792703.8125\n",
      "500 400268.78125\n",
      "750 345150.09375\n",
      "1000 286165.375\n",
      "1250 217393.375\n",
      "1500 140575.875\n",
      "1750 68729.140625\n",
      "2000 22814.84765625\n",
      "2250 5327.1279296875\n",
      "2500 1045.66650390625\n",
      "2750 190.31539916992188\n",
      "3000 30.032869338989258\n",
      "3250 3.7385342121124268\n",
      "3500 0.3447841703891754\n",
      "3750 0.022456083446741104\n",
      "4000 0.0009877184638753533\n",
      "4250 3.16251753247343e-05\n",
      "4500 6.0757774917874485e-06\n",
      "4750 3.5873563319910318e-06\n",
      "5000 2.4432411009911448e-06\n",
      "5250 1.7495185602456331e-06\n",
      "5500 1.4415163605008274e-06\n",
      "5750 1.2026939657516778e-06\n",
      "6000 8.386195986531675e-07\n",
      "6250 6.79257937008515e-07\n",
      "6500 6.435911927837878e-07\n",
      "6750 5.500369297806174e-07\n",
      "7000 4.2026658775284886e-07\n",
      "7250 3.0630690162070096e-07\n",
      "7500 9.318500815425068e-07\n",
      "7750 4.7309004003182054e-07\n",
      "8000 2.7687416076660156\n",
      "8250 2.6683846954256296e-07\n",
      "8500 2.6197085389867425e-07\n",
      "8750 3.2390380511060357e-07\n",
      "9000 3.5832636058330536e-07\n",
      "9250 0.0001452863507438451\n",
      "9500 2.713495632633567e-07\n",
      "9750 2.563392627052963e-07\n"
     ]
    }
   ],
   "source": [
    "model = TFIDF_NN(vectorizer)\n",
    "\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "learning_rate = 1e-2\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for t in range(10000):\n",
    "    y_pred = model(df[\"text\"])\n",
    "    y_true = torch.tensor(np.array(df[[\"x\", \"y\"]])).float()\n",
    "    loss = loss_fn(y_pred, y_true)\n",
    "    if t % 250 == 0:\n",
    "        print(t, loss.item())\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "52ac3ffe-257c-4766-b09b-d43845dfb875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[188.561735, 362.14572 ],\n",
       "       [188.561735, 362.14572 ],\n",
       "       [188.561735, 362.14572 ],\n",
       "       [188.561735, 362.14572 ],\n",
       "       [188.561735, 362.14572 ],\n",
       "       [211.30841 ,  84.773225],\n",
       "       [211.30841 ,  84.773225],\n",
       "       [211.30841 ,  84.773225],\n",
       "       [211.30841 ,  84.773225],\n",
       "       [211.30841 ,  84.773225],\n",
       "       [211.30841 ,  84.773225],\n",
       "       [211.30841 ,  84.773225],\n",
       "       [211.30841 ,  84.773225],\n",
       "       [211.30841 ,  84.773225],\n",
       "       [211.30841 ,  84.773225],\n",
       "       [211.30841 ,  84.773225],\n",
       "       [211.30841 ,  84.773225],\n",
       "       [211.30841 ,  84.773225],\n",
       "       [211.30841 ,  84.773225],\n",
       "       [211.30841 ,  84.773225],\n",
       "       [211.30841 ,  84.773225],\n",
       "       [587.06696 , 403.45715 ],\n",
       "       [587.06696 , 403.45715 ],\n",
       "       [587.06696 , 403.45715 ],\n",
       "       [587.06696 , 403.45715 ],\n",
       "       [587.06696 , 403.45715 ],\n",
       "       [587.06696 , 403.45715 ],\n",
       "       [587.06696 , 403.45715 ],\n",
       "       [587.06696 , 403.45715 ],\n",
       "       [408.21438 , 120.81297 ],\n",
       "       [408.21438 , 120.81297 ],\n",
       "       [408.21438 , 120.81297 ],\n",
       "       [408.21438 , 120.81297 ],\n",
       "       [ 33.95794 , 346.37247 ],\n",
       "       [ 33.95794 , 346.37247 ],\n",
       "       [ 33.95794 , 346.37247 ],\n",
       "       [ 33.95794 , 346.37247 ],\n",
       "       [ 33.95794 , 346.37247 ],\n",
       "       [585.8639  ,  85.378095],\n",
       "       [370.181665,  50.81915 ],\n",
       "       [370.181665,  50.81915 ],\n",
       "       [353.08803 ,  29.615225],\n",
       "       [353.08803 ,  29.615225],\n",
       "       [279.98351 , 254.348975],\n",
       "       [311.321435, 205.17695 ],\n",
       "       [452.94551 , 203.26715 ],\n",
       "       [452.94551 , 203.26715 ],\n",
       "       [694.28631 , 370.377345],\n",
       "       [694.28631 , 370.377345],\n",
       "       [694.28631 , 370.377345],\n",
       "       [694.28631 , 370.377345],\n",
       "       [694.28631 , 370.377345],\n",
       "       [694.28631 , 370.377345],\n",
       "       [694.28631 , 370.377345],\n",
       "       [694.28631 , 370.377345],\n",
       "       [452.94551 , 203.26715 ],\n",
       "       [267.49623 , 303.395295],\n",
       "       [267.49623 , 303.395295],\n",
       "       [267.49623 , 303.395295],\n",
       "       [692.63906 , 163.502   ],\n",
       "       [692.63906 , 163.502   ],\n",
       "       [692.63906 , 163.502   ],\n",
       "       [692.63906 , 163.502   ],\n",
       "       [655.26521 , 196.323345],\n",
       "       [655.26521 , 196.323345],\n",
       "       [147.54123 , 445.77432 ],\n",
       "       [689.52361 , 239.277725],\n",
       "       [689.52361 , 239.277725],\n",
       "       [689.52361 , 239.277725],\n",
       "       [147.54123 , 445.77432 ],\n",
       "       [147.54123 , 445.77432 ],\n",
       "       [147.54123 , 445.77432 ],\n",
       "       [147.54123 , 445.77432 ],\n",
       "       [147.54123 , 445.77432 ],\n",
       "       [147.54123 , 445.77432 ],\n",
       "       [147.54123 , 445.77432 ],\n",
       "       [147.54123 , 445.77432 ],\n",
       "       [147.54123 , 445.77432 ],\n",
       "       [147.54123 , 445.77432 ],\n",
       "       [147.54123 , 445.77432 ],\n",
       "       [147.54123 , 445.77432 ],\n",
       "       [147.54123 , 445.77432 ],\n",
       "       [147.54123 , 445.77432 ],\n",
       "       [147.54123 , 445.77432 ],\n",
       "       [228.840605, 424.62387 ],\n",
       "       [228.840605, 424.62387 ],\n",
       "       [533.25933 , 205.17695 ],\n",
       "       [533.25933 , 205.17695 ],\n",
       "       [533.25933 , 205.17695 ],\n",
       "       [533.25933 , 205.17695 ],\n",
       "       [162.02576 , 327.04355 ],\n",
       "       [162.02576 , 327.04355 ],\n",
       "       [162.02576 , 327.04355 ],\n",
       "       [188.561735, 362.14572 ],\n",
       "       [188.561735, 362.14572 ],\n",
       "       [188.561735, 362.14572 ],\n",
       "       [188.561735, 362.14572 ],\n",
       "       [188.561735, 362.14572 ],\n",
       "       [188.561735, 362.14572 ],\n",
       "       [211.30841 ,  84.773225]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137df2bd-051e-4fbb-a516-ae6323e31ffc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
